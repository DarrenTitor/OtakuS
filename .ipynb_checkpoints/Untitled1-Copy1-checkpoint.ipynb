{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['JAVA_HOME'] = 'C:\\Program Files\\Java\\jdk1.8.0_281'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"E:\\spark-3.1.1\")\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, QuantileDiscretizer, MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import max as sparkMax\n",
    "from pyspark.sql.functions import udf\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "# spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('archive/anime_cleaned.csv',\n",
    "                    header='true', \n",
    "                    inferSchema='true')\n",
    "# df2 = spark.read.csv('archive/users_cleaned.csv',\n",
    "#                     header='true', \n",
    "#                     inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_columns = ['type','episodes','status','airing','score','scored_by','rank', \n",
    "                  'popularity','members','favorites','genre',  'anime_id',]\n",
    "useless_columns = [col for col in df.columns if col not in useful_columns]\n",
    "\n",
    "df = df.drop(*useless_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6668, 12)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_onehot_encoder(_df, column_name, drop_origin=True):\n",
    "    ohe = pyspark.ml.feature.OneHotEncoder()\n",
    "    ohe.setInputCols([column_name])\n",
    "    ohe.setOutputCols([column_name+'_vector'])\n",
    "    ohe_model = ohe.fit(_df)\n",
    "    ohe_model.setOutputCols([column_name+'_vector'])\n",
    "    ohe_model.getHandleInvalid()\n",
    "    _df = ohe_model.transform(_df)\n",
    "    if drop_origin:\n",
    "        _df = _df.drop(column_name)\n",
    "    \n",
    "    return _df\n",
    "\n",
    "\n",
    "def array2vec(genreIndexes, indexSize):\n",
    "    genreIndexes.sort()\n",
    "\n",
    "    fill_list = [1.0 for _ in range(len(genreIndexes))]\n",
    "    return Vectors.sparse(indexSize, genreIndexes, fill_list)\n",
    "\n",
    "\n",
    "def apply_multihot_encoder(movieSamples, col_name, _splitter = \", \", drop_origin=True):\n",
    "    if col_name not in movieSamples.columns:\n",
    "        return None\n",
    "    all_cols_list = movieSamples.columns\n",
    "    all_cols_list.remove(\"anime_id\")\n",
    "    samplesWithGenre = movieSamples.withColumn(col_name+'_x',F.explode(\n",
    "        F.split(F.col(col_name), _splitter).cast(ArrayType(StringType()))))\n",
    "    genreIndexer = StringIndexer(inputCol=col_name+'_x', outputCol=col_name+\"Index\")\n",
    "    StringIndexerModel = genreIndexer.fit(samplesWithGenre)\n",
    "    genreIndexSamples = StringIndexerModel.transform(samplesWithGenre).withColumn(col_name+\"IndexInt\",\n",
    "                                                                                  F.col(col_name+\"Index\").cast(IntegerType()))\n",
    "    indexSize = genreIndexSamples.agg(sparkMax(F.col(col_name+\"IndexInt\"))).head()[0] + 1\n",
    "    processedSamples = genreIndexSamples.groupBy('anime_id').agg(\n",
    "        F.array_distinct(F.collect_list(col_name+'IndexInt')).alias(col_name+\"Indexes\"), \n",
    "        *[F.max(i).alias(i) for i in all_cols_list]\n",
    "    ).withColumn(\"indexSize\", F.lit(indexSize))\n",
    "    finalSample = processedSamples.withColumn(col_name+\"_vector\", udf(array2vec, VectorUDT())(F.col(col_name+\"Indexes\"), F.col(\"indexSize\")))\n",
    "#     finalSample.printSchema()\n",
    "    finalSample = finalSample.drop(col_name+\"Indexes\", \"indexSize\")\n",
    "    \n",
    "\n",
    "    finalSample.show(1, False, vertical=True)\n",
    "    return finalSample\n",
    "#     movieSamples = movieSamples.join(finalSample, on=['anime_id'], how='left_outer')\n",
    "#     movieSamples.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_id_list = df.select('anime_id').sample(0.15, seed=0).collect()\n",
    "anime_id_set = set([row.anime_id for row in anime_id_list])\n",
    "del anime_id_list\n",
    "\n",
    "# user_id_list = df2.select('user_id').sample(0.03, seed=0).collect()\n",
    "# user_id_set = set([row.user_id for row in user_id_list])\n",
    "# del user_id_list\n",
    "\n",
    "cat_feature = ['anime_id', 'type', 'status','airing', 'genre']\n",
    "num_feature = ['score', 'scored_by', 'rank', 'popularity','members','favorites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df[\"anime_id\"].isin(anime_id_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------\n",
      " anime_id     | 6336                                            \n",
      " type         | OVA                                             \n",
      " episodes     | 7                                               \n",
      " status       | Finished Airing                                 \n",
      " airing       | False                                           \n",
      " score        | 8.31                                            \n",
      " scored_by    | 23492                                           \n",
      " rank         | 232.0                                           \n",
      " popularity   | 1481.0                                          \n",
      " members      | 52688.0                                         \n",
      " favorites    | 1066                                            \n",
      " genre        | Action, Drama, Mecha, Military, Sci-Fi, Space   \n",
      " genre_vector | (84,[1,4,5,12,23,26],[1.0,1.0,1.0,1.0,1.0,1.0]) \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = apply_multihot_encoder(df, 'genre')\n",
    "df = df.drop('genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------\n",
      " anime_id            | 6336                                            \n",
      " episodes            | 7                                               \n",
      " score               | 8.31                                            \n",
      " scored_by           | 23492                                           \n",
      " rank                | 232.0                                           \n",
      " popularity          | 1481.0                                          \n",
      " members             | 52688.0                                         \n",
      " favorites           | 1066                                            \n",
      " genre_vector        | (84,[1,4,5,12,23,26],[1.0,1.0,1.0,1.0,1.0,1.0]) \n",
      " type_index_vector   | (6,[1],[1.0])                                   \n",
      " status_index_vector | (2,[0],[1.0])                                   \n",
      " airing_index_vector | (2,[0],[1.0])                                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "to_label = ['type', 'status', 'airing']\n",
    "for col in to_label:\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=col+\"_index\") \n",
    "    df = indexer.fit(df).transform(df) \n",
    "    df = df.drop(col)\n",
    "# df.show(1, False, True)\n",
    "index_columns = [i+'_index' for i in to_label]\n",
    "for i in index_columns:\n",
    "    df = apply_onehot_encoder(df, i)\n",
    "df.show(1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf\n",
    "unlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- episodes: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- scored_by: string (nullable = true)\n",
      " |-- rank: double (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- members: double (nullable = true)\n",
      " |-- favorites: integer (nullable = true)\n",
      " |-- genre_vector: vector (nullable = true)\n",
      " |-- type_index_vector: vector (nullable = true)\n",
      " |-- status_index_vector: vector (nullable = true)\n",
      " |-- airing_index_vector: vector (nullable = true)\n",
      "\n",
      "-RECORD 0--------------------------------------------------------------\n",
      " anime_id            | 6336                                            \n",
      " episodes            | 7                                               \n",
      " score               | 8.31                                            \n",
      " scored_by           | 23492                                           \n",
      " rank                | 232.0                                           \n",
      " popularity          | 1481.0                                          \n",
      " members             | 52688.0                                         \n",
      " favorites           | 1066                                            \n",
      " genre_vector        | (84,[1,4,5,12,23,26],[1.0,1.0,1.0,1.0,1.0,1.0]) \n",
      " type_index_vector   | (6,[1],[1.0])                                   \n",
      " status_index_vector | (2,[0],[1.0])                                   \n",
      " airing_index_vector | (2,[0],[1.0])                                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: column  episodes\n",
      "VectorUDT\n",
      "processing: column  scored_by\n",
      "VectorUDT\n",
      "processing: column  favorites\n",
      "VectorUDT\n",
      "processing: column  rank\n",
      "VectorUDT\n",
      "processing: column  popularity\n",
      "VectorUDT\n",
      "processing: column  members\n",
      "VectorUDT\n",
      "processing: column  score\n",
      "VectorUDT\n"
     ]
    }
   ],
   "source": [
    "to_num_and_then_scale = [\"episodes\", \"scored_by\", \"favorites\",\n",
    "               'rank', 'popularity', 'members', 'score']\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "for i in to_num_and_then_scale:\n",
    "    df = df.withColumn(i+\"_num\", df[i].cast(DoubleType()))\n",
    "    df = df.drop(i)\n",
    "    df = df.fillna(0, subset=[i+\"_num\"])\n",
    "    print('processing: column ', i)\n",
    "    assembler = VectorAssembler(inputCols=[i+\"_num\"],outputCol=i+\"_Vect\")\n",
    "    df = assembler.transform(df)\n",
    "#     df.show(1, False ,True)\n",
    "#     print(df.schema[i+\"_Vect\"].dataType)\n",
    "#     df = df.withColumn(i+\"_Vect\", Vectors.dense())\n",
    "#     print(df.schema[i+\"_Vect\"].dataType)\n",
    "\n",
    "    sscaler = StandardScaler(inputCol=i+\"_Vect\", outputCol='standard'+i+'_v')\n",
    "    df = sscaler.fit(df).transform(df)\n",
    "#     df = smodel.transform(df).drop(i+\"_Vect\")\n",
    "    unlist = udf(lambda x: float(list(x)[0]), DoubleType())\n",
    "\n",
    "    df = df.withColumn(i+'_stdscaled', unlist('standard'+i+'_v'))        \n",
    "\n",
    "    df = df.drop(i+\"_num\", 'standard'+i+'_v', i+\"_Vect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('anime_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genre_vector: vector (nullable = true)\n",
      " |-- type_index_vector: vector (nullable = true)\n",
      " |-- status_index_vector: vector (nullable = true)\n",
      " |-- airing_index_vector: vector (nullable = true)\n",
      " |-- episodes_stdscaled: double (nullable = true)\n",
      " |-- scored_by_stdscaled: double (nullable = true)\n",
      " |-- favorites_stdscaled: double (nullable = true)\n",
      " |-- rank_stdscaled: double (nullable = true)\n",
      " |-- popularity_stdscaled: double (nullable = true)\n",
      " |-- members_stdscaled: double (nullable = true)\n",
      " |-- score_stdscaled: double (nullable = true)\n",
      "\n",
      "-RECORD 0---------------------------------------------------------------\n",
      " genre_vector         | (84,[1,4,5,12,23,26],[1.0,1.0,1.0,1.0,1.0,1.0]) \n",
      " type_index_vector    | (6,[1],[1.0])                                   \n",
      " status_index_vector  | (2,[0],[1.0])                                   \n",
      " airing_index_vector  | (2,[0],[1.0])                                   \n",
      " episodes_stdscaled   | 0.2543923113347032                              \n",
      " scored_by_stdscaled  | 0.45694530665385064                             \n",
      " favorites_stdscaled  | 0.46619812595480015                             \n",
      " rank_stdscaled       | 0.0717266335137606                              \n",
      " popularity_stdscaled | 0.4274914883737552                              \n",
      " members_stdscaled    | 0.5762147924353819                              \n",
      " score_stdscaled      | 8.424242964630507                               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_num_scale = [\"favorites\"]\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "for i in to_num_scale:\n",
    "    assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\")\n",
    "    scaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
    "    pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "    df = pipeline.fit(df).transform(df).withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\"))\n",
    "\n",
    "    scaler = StandardScaler(inputCol=i+\"_Vect\", outputCol='standard'+i+'_v',\n",
    "                        withStd=True, withMean=False)\n",
    "    smodel = scaler.fit(df)\n",
    "    df = smodel.transform(df).drop(i+\"_Vect\")\n",
    "    unlist = udf(lambda x: float(list(x)[0]), DoubleType())\n",
    "\n",
    "    df = df.withColumn('standard'+i, unlist('standard'+i+'_v'))        \n",
    "\n",
    "    df = df.drop(i, 'standard'+i+'_v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_scored_by\n",
      "+--------+-----+----------+-------+--------------------+---------+-----------+-----------+---------+-------------+------------+----------------+-------------------+------------------+\n",
      "|anime_id| rank|popularity|members|        genre_vector|typeIndex|statusIndex|airingIndex|num_score|num_scored_by|num_episodes|favorites_Scaled|  standardfavorites|num_scored_by_Vect|\n",
      "+--------+-----+----------+-------+--------------------+---------+-----------+-----------+---------+-------------+------------+----------------+-------------------+------------------+\n",
      "|    6336|232.0|    1481.0|52688.0|(84,[1,4,5,12,23,...|      1.0|        0.0|        0.0|     8.31|      23492.0|         7.0|           0.026|0.46619812595480015|         [23492.0]|\n",
      "+--------+-----+----------+-------+--------------------+---------+-----------+-----------+---------+-------------+------------+----------------+-------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "VectorUDT\n",
      "+--------+-----+----------+-------+--------------------+---------+-----------+-----------+---------+-------------+------------+----------------+-------------------+------------------+--------------------+\n",
      "|anime_id| rank|popularity|members|        genre_vector|typeIndex|statusIndex|airingIndex|num_score|num_scored_by|num_episodes|favorites_Scaled|  standardfavorites|num_scored_by_Vect|num_scored_by_Scaled|\n",
      "+--------+-----+----------+-------+--------------------+---------+-----------+-----------+---------+-------------+------------+----------------+-------------------+------------------+--------------------+\n",
      "|    6336|232.0|    1481.0|52688.0|(84,[1,4,5,12,23,...|      1.0|        0.0|        0.0|     8.31|      23492.0|         7.0|           0.026|0.46619812595480015|         [23492.0]| 0.04711573559672845|\n",
      "+--------+-----+----------+-------+--------------------+---------+-----------+-----------+---------+-------------+------------+----------------+-------------------+------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_num_scale = [\"num_scored_by\"]\n",
    "\n",
    "to_array = F.udf(lambda v: v.toArray().tolist(), ArrayType(DoubleType()))\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "for i in to_num_scale:\n",
    "    print(i)\n",
    "    assembler = VectorAssembler(inputCols=[i],outputCol=i+\"_Vect\")\n",
    "    df = assembler.transform(df)\n",
    "    df.show(1)\n",
    "    print(df.schema[i+\"_Vect\"].dataType)\n",
    "#     df = df.withColumn(i+\"_Vect\", Vectors.dense())\n",
    "#     print(df.schema[i+\"_Vect\"].dataType)\n",
    "    mmscaler = MinMaxScaler(inputCol=i+\"_Vect\", outputCol=i+\"_Scaled\")\n",
    "    df = mmscaler.fit(df).transform(df)\n",
    "    df = df.withColumn(i+\"_Scaled\", unlist(i+\"_Scaled\"))\n",
    "    df.show(1)\n",
    "    sscaler = StandardScaler(inputCol=i+\"_Vect\", outputCol='standard'+i+'_v',\n",
    "                        withStd=True, withMean=False)\n",
    "    smodel = sscaler.fit(df)\n",
    "    df = smodel.transform(df).drop(i+\"_Vect\")\n",
    "    unlist = udf(lambda x: float(list(x)[0]), DoubleType())\n",
    "\n",
    "    df = df.withColumn('standard'+i, unlist('standard'+i+'_v'))        \n",
    "\n",
    "    df = df.drop(i, 'standard'+i+'_v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- rank: double (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- members: double (nullable = true)\n",
      " |-- genre_vector: vector (nullable = true)\n",
      " |-- typeIndex: double (nullable = false)\n",
      " |-- statusIndex: double (nullable = false)\n",
      " |-- airingIndex: double (nullable = false)\n",
      " |-- num_score: double (nullable = true)\n",
      " |-- num_episodes: double (nullable = true)\n",
      " |-- favorites_Scaled: double (nullable = true)\n",
      " |-- standardfavorites: double (nullable = true)\n",
      " |-- num_scored_by_Scaled: double (nullable = true)\n",
      " |-- standardnum_scored_by: double (nullable = true)\n",
      "\n",
      "-RECORD 0----------------------------------------------------------------\n",
      " anime_id              | 6336                                            \n",
      " rank                  | 232.0                                           \n",
      " popularity            | 1481.0                                          \n",
      " members               | 52688.0                                         \n",
      " genre_vector          | (84,[1,4,5,12,23,26],[1.0,1.0,1.0,1.0,1.0,1.0]) \n",
      " typeIndex             | 1.0                                             \n",
      " statusIndex           | 0.0                                             \n",
      " airingIndex           | 0.0                                             \n",
      " num_score             | 8.31                                            \n",
      " num_episodes          | 7.0                                             \n",
      " favorites_Scaled      | 0.026                                           \n",
      " standardfavorites     | 0.46619812595480015                             \n",
      " num_scored_by_Scaled  | 0.04711573559672845                             \n",
      " standardnum_scored_by | 0.45694530665385064                             \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(1, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('allnums.json', 'w') as f:\n",
    "    f.write(df.toPandas().to_json(orient='records', lines=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
